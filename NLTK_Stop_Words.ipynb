{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH+349JqxhkQQp9wWZ7QEN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasvx273/NLP_Python/blob/main/NLTK_Stop_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonte do estudo: https://pythonspot.com/nltk-stop-words/\n",
        "\n",
        "Esse caderno será usado para testes envolvendo NLTK e Stop_Words\n",
        "\n",
        "--------------------------------\n"
      ],
      "metadata": {
        "id": "XgHUkoZDvGQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Natural Language Processing with PythonNatural language processing (nlp) is a research field that presents many challenges such as natural language understanding.\n",
        "\n",
        "Stop words are common words like ‘the’, ‘and’, ‘I’, etc. that are very frequent in text, and so don’t convey insights into the specific topic of a document. We can remove these stop words from the text in a given corpus to clean up the data, and identify words that are more rare and potentially more relevant to what we’re interested in.\n",
        "\n",
        "Text may contain stop words like ‘the’, ‘is’, ‘are’. Stop words can be filtered from the text to be processed. There is no universal list of stop words in nlp research, however the nltk module contains a list of stop words."
      ],
      "metadata": {
        "id": "nqmX4BIQvaOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Jyshf-7u9vA"
      },
      "outputs": [],
      "source": [
        "# Here’s a list of most commonly used words in English\n",
        "\n",
        "N = [ 'stop', 'the', 'to', 'and', 'a', 'in', 'it', 'is', 'I', 'that', 'had', 'on', 'for', 'were', 'was']\n",
        "\n",
        "print(N)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With nltk you don’t have to define every stop word manually**. Stop words are frequently used words that carry very little meaning. Stop words are words that are so common they are basically ignored by typical tokenizers.\n",
        "\n",
        "By default, **NLTK** (Natural Language Toolkit) **includes a list of 40 stop words,** including: “a”, “an”, “the”, “of”, “in”, etc.\n",
        "\n",
        "The stopwords in nltk are the most common words in data. They are words that you do not want to use to describe the topic of your content. They are pre-defined and cannot be removed."
      ],
      "metadata": {
        "id": "aSPmi27BvwMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "2ejifK4yv4_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        " \n",
        "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
        "words = word_tokenize(data)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lykKNavDwcP4",
        "outputId": "09f0796d-19e5-4463-daef-9aa3d5e30270"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'dull', 'boy', '.', 'All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting rid of stop words makes a lot of sense for any Natural Language Processing task. In this code you will see how you can get rid of these ugly stop words from your texts."
      ],
      "metadata": {
        "id": "6_mz6aEewtXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "kAQhofHfwt8_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK Stopword List**\n",
        "\n",
        "So stopwords are words that are very common in human language but are generally not useful because they represent particularly common words such as “the”, “of”, and “to”.\n",
        "\n",
        "If you get the error NLTK stop words not found, make sure to download the stop words after installing nltk."
      ],
      "metadata": {
        "id": "N2sPdBAew2CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "print(stops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ujUsFjnw3Tf",
        "outputId": "b401c9a1-6f3f-4184-9518-f027f0d79342"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'of', 'is', 'wouldn', 'very', \"she's\", 'having', 'did', 'has', 'hadn', 'each', 'himself', 'after', 'there', 'and', 'more', 'own', \"you've\", 'mustn', 'both', 'down', 'isn', 'just', \"mustn't\", 'than', \"you'll\", 'have', 'about', 'against', 'ma', \"should've\", 'here', 'are', 'how', 'll', 'was', 'does', 'been', 'during', 'above', 'hasn', 'who', 'am', 'we', \"hasn't\", 'by', 'most', 'being', 'doing', 'the', 'won', 'before', 'a', 'shouldn', 'that', 'an', 'where', \"isn't\", \"it's\", 'again', 'theirs', 'but', 'can', 'when', 'whom', \"wouldn't\", 'those', 'at', 'm', 'or', 'our', 'what', 'it', 'she', 'doesn', 'do', 'through', 'off', \"shan't\", 't', \"wasn't\", 'yourself', 'them', 'further', 'aren', 'needn', \"needn't\", 'so', 'mightn', 'because', 'wasn', 'its', 'up', \"you're\", 're', 'as', 'not', 'below', 'any', 'yours', 'some', \"won't\", 'under', 'ourselves', 'his', 'now', \"mightn't\", 'same', 'over', \"that'll\", 'while', 'between', 'which', 'hers', 'haven', 'their', 'to', 'nor', 'shan', 'they', 'these', 'my', 'themselves', 'for', 'only', 'don', \"shouldn't\", 'your', 'be', 's', 'then', 'o', \"didn't\", 'ain', 'itself', 'with', 'into', \"doesn't\", 'no', 'weren', \"aren't\", 'until', 'from', 'her', 'if', 'once', 'other', 've', 'should', 'too', 'had', 'you', 'myself', 'few', \"couldn't\", 'i', 'd', 'this', 'y', 'ours', 'such', 'he', 'why', 'herself', \"don't\", 'all', \"hadn't\", \"haven't\", 'didn', 'him', 'were', 'out', 'on', 'me', \"weren't\", 'yourselves', 'will', \"you'd\", 'in', 'couldn'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can do that for different languages, so you can configure fro the language you need:\n",
        "\n",
        "stops = set(stopwords.words('german'))\n",
        "\n",
        "stops = set(stopwords.words('indonesia'))\n",
        "\n",
        "stops = set(stopwords.words('**portuguese**'))\n",
        "\n",
        "stops = set(stopwords.words('spanish'))"
      ],
      "metadata": {
        "id": "VEk-0tpdw_Vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter stop words nltk**\n",
        "\n",
        "We will use a string (data) as text. Of course you can also do this with a text file as input. If you want to use a text file instead."
      ],
      "metadata": {
        "id": "Xnqtg8BLxLcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        " \n",
        "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
        "stopWords = set(stopwords.words('english'))\n",
        "words = word_tokenize(data)\n",
        "wordsFiltered = []\n",
        "\n",
        "for w in words:\n",
        "    if w not in stopWords:\n",
        "        wordsFiltered.append(w)\n",
        "\n",
        "print(wordsFiltered)\n",
        "print(len(stopWords))\n",
        "print(stopWords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7bo7bL0xFFc",
        "outputId": "c2036d84-600e-4ce5-8367-a72138051cb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['All', 'work', 'play', 'makes', 'jack', 'dull', 'boy', '.', 'All', 'work', 'play', 'makes', 'jack', 'dull', 'boy', '.']\n",
            "179\n",
            "{'of', 'is', 'wouldn', 'very', \"she's\", 'having', 'did', 'has', 'hadn', 'each', 'himself', 'after', 'there', 'and', 'more', 'own', \"you've\", 'mustn', 'both', 'down', 'isn', 'just', \"mustn't\", 'than', \"you'll\", 'have', 'about', 'against', 'ma', \"should've\", 'here', 'are', 'how', 'll', 'was', 'does', 'been', 'during', 'above', 'hasn', 'who', 'am', 'we', \"hasn't\", 'by', 'most', 'being', 'doing', 'the', 'won', 'before', 'a', 'shouldn', 'that', 'an', 'where', \"isn't\", \"it's\", 'again', 'theirs', 'but', 'can', 'when', 'whom', \"wouldn't\", 'those', 'at', 'm', 'or', 'our', 'what', 'it', 'she', 'doesn', 'do', 'through', 'off', \"shan't\", 't', \"wasn't\", 'yourself', 'them', 'further', 'aren', 'needn', \"needn't\", 'so', 'mightn', 'because', 'wasn', 'its', 'up', \"you're\", 're', 'as', 'not', 'below', 'any', 'yours', 'some', \"won't\", 'under', 'ourselves', 'his', 'now', \"mightn't\", 'same', 'over', \"that'll\", 'while', 'between', 'which', 'hers', 'haven', 'their', 'to', 'nor', 'shan', 'they', 'these', 'my', 'themselves', 'for', 'only', 'don', \"shouldn't\", 'your', 'be', 's', 'then', 'o', \"didn't\", 'ain', 'itself', 'with', 'into', \"doesn't\", 'no', 'weren', \"aren't\", 'until', 'from', 'her', 'if', 'once', 'other', 've', 'should', 'too', 'had', 'you', 'myself', 'few', \"couldn't\", 'i', 'd', 'this', 'y', 'ours', 'such', 'he', 'why', 'herself', \"don't\", 'all', \"hadn't\", \"haven't\", 'didn', 'him', 'were', 'out', 'on', 'me', \"weren't\", 'yourselves', 'will', \"you'd\", 'in', 'couldn'}\n"
          ]
        }
      ]
    }
  ]
}